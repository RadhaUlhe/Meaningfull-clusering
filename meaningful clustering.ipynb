{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMWn5qA9x9Ma5gaFzi+hv9y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iXqb906Nvr4A"},"outputs":[],"source":["class KmeansInterp(KMeans):\n","\n","  def __init__(self, ordered_feature_names, feature_importance_method='wcss_min', **kwargs) :\n","    super(KMeansInterp, self).__init__(**kwargs)         ## call kmeanns on given dataframe\n","    self.feature_importance_method = feature_importance_method\n","    self.ordered_feature_names = ordered_feature_names\n","\n","\n","  def fit(self, X, y=None, sample_weight=None):\n","\n","    super().fit(X=x, y=y, sample_weight=sample_weight)\n","\n","    if self.feature_importance_method = \"wcss_min\":\n","      self.feature_importances = self.get_feature_wcss_min()\n","\n","    if self.feature_importance_method = \"unsup2sup\":\n","      self.feature_importances = self.get_feature_imp_unsup2sup(X)\n","\n","    else:\n","      raise Exception(f\"{self.feature_importances_method} is not available\")\n","\n","\n","  def fit_predict(self, X, y=None, sample_weight=None):\n","    return super().fit_predict(X=X, y=y, sample_weight=sample_weight)\n","\n","  def predict(self, X, sample_weight=None)\n","\n","    self.labels_= super().predict(X=X, sample_weight = sample_weight)\n","\n","    if self.feature_importance_method = \"wcss_min\":\n","      self.feature_importances = self.get_feature_wcss_min()\n","\n","    if self.feature_importance_method = \"unsup2sup\":\n","      self.feature_importances = self.get_feature_imp_unsup2sup(X)\n","\n","    else:\n","      raise Exception(f\"{self.feature_importances_method} is not available\")\n","\n","\n","  def get_feature_wcss_min(self):\n","\n","    labels = self.n_clusters\n","    centroids = self.cluster_centers_\n","    centroids = np.vectorize(lambda x: np.abs(x))(centroids)\n","    sorted_centroid_features_idx = centroids.argsort(axis=1)[:,::-1]        ##sorted feature index for each centroid\n","\n","    cluster_feature_weights = {}\n","\n","    for label, centriod in zip(range(labels), sorted_centroid_features_idx):   ### get weight of  each feature which is distance moved by centroid by a feature of wcss MINIMIZATION, highter the disance moved, higher the impact of feature\n","        ordered_cluster_feature_weights = centroids[label][sorted_centroid_features_idx[label]]\n","        ordered_cluster_features = [self.ordered_feature_names[feature] for feature in centroid]\n","        cluster_feature_weights[label] = list(zip(ordered_cluster_features, list(np.around(np.array(ordered_cluster_feature_weights),2))))\n","\n","\n","    return cluster_feature_weights\n","\n","\n","\n","    def get_feature_imp_unsup2sup(self,X):\n","\n","      try:\n","        from sklearn.ensemble import RandoForestClassifier\n","\n","      except ImportError as IE:\n","\n","        raise Exception(\"Please install\")\n","\n","      cluster_feature_weights = {}\n","\n","      for label in range(self.n_clusters):\n","        binary_enc = np.vectorize(lambda x:1 if x == label else 0)(self.labels_)  ## covert the problem into binary classifier\n","        clf = RandoForestClassifier()                                             ## run random fores and get important features for cluster\n","        clf.fit(X,binary_enc)\n","\n","\n","      sorted_feature_weight_idxes = np.arsort(list(np.arround(np.array(clf.feature_importances_),2)))[::-1]\n","      ordered_cluster_features = np.take_along_axis(np.array(self.ordered_feature_names),sorted_feature_weight_idxes, axis=0)\n","      ordered_cluster_feature_weights = np.take_along_axis(np.array(clf.feature_importances_), sorted_feature_weight_idxes, axis=0)\n","\n","      cluster_feature_weights[label] = list(zip(ordered_cluster_features, list(np.around(np.array(ordered_cluster_feature_weights),2))))\n","\n","      return cluster_feature_weights\n","\n","\n","\n","\n"]},{"cell_type":"code","source":["from plotly.express import px\n","\n","def train_segmentation_model(train_data):\n","\n","  kms=KMeansInterp(n_clusters=4,\n","                   ordered_feature_names = [\"col1\", \"clo2\"],\n","                    feature_importance_method = 'unsup2sup'\n","                  ).fit(train_data[[\"col1\",\"col2\"]])\n","\n","  train_data[\"clusters\"] = kms.labels_\n","\n","  for i in range(len(train_data)):\n","    cluster_no = train_data.loc[i,\"clusters\"]\n","    train_data.at[i,\"cluster_vector\"] = kms.feature_importances_[cluster_no][:4]\n","\n","  print(f\"silhouette score:{silhhouette_score(df[[\"clo1\",\"clo2\"]], model.labels_)}\")\n","\n","\n","def convert(tup,di):\n","  for a,b in tup:\n","    di.setdefault(a,[]).append(b)\n","\n","\n","def get_cluster_position(model, train_data):\n","  cluster_labels = pd.DataFrame()\n","\n","  cluster_labels.at[0,\"imp_features\"] = model.feature_importances_[0][:4]\n","  cluster_labels.at[1,\"imp_features\"] = model.feature_importances_[1][:4]\n","  cluster_labels.at[2,\"imp_features\"] = model.feature_importances_[2][:4]\n","  cluster_labels.at[3,\"imp_features\"] = model.feature_importances_[3][:4]\n","\n","  cluster_labels[\"cluster\"] = cluster_labels.index\n","  cluster_labels[\"records\"] = train_data.groupby([\"clusters\"]).size()\n","\n","  tup_list = []\n","  for i in range(0,len(cluster_labels)):\n","    tup_list = tup_list + cluster_labels.loc[i,\"imp_features\"]\n","\n","  dictionary = {}\n","  di = convert(tup_list, dictionary)\n","\n","  cluster_df = pd.DataFrame(di)\n","  cluster_df = pd.concat([cluster_df,cluster_labels], axis=1)\n","\n","  ## draw cluster ##\n","  fig = px.scatter_3d(cluster_df, x=\"clust1\", y=\"clust2\", z=\"clust3\",\n","                      color=\"cluster\", opacity=0.8, size='%guests', size_max=80)\n","\n","  fig.show()\n","\n","  return cluster_df"],"metadata":{"id":"eYAT54J17fjg"},"execution_count":null,"outputs":[]}]}